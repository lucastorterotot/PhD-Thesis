\section{Arbres de décision améliorés}\label{chapter-ML-section-XGB}
% https://docs.google.com/presentation/d/1WTeOmpcj3Fr4KU2-ZASnBPjyNd5OddY6Bmr9YYZaXDs/edit#slide=id.g53a3150aec_0_7
La librairie
\XGBOOST~\cite{xgboost}
(\emph{eXtreme Gradient Boosting})
permet de construire des
arbres de décision améliorés.
De nombreuses compétitions Kaggle~\cite{kaggle_challenge} ont été remportées grâce eux.
Ils présentent l'avantage d'être généralement plus à entraîner que des réseaux de neurones présentés section~\ref{chapter-ML-section-DNN},
et peuvent fournir des prédictions même si une des entrées est manquante, ce qui n'est pas le cas des réseaux de neurones.
\subsection{Arbres de décision}
Les arbres de décision sont une succession de questions,
dont les réponses mènent à un résultat final,
comme illustré sur la figure~\ref{fig-decision_tree_schema}.
Chaque réponse à une question créé une \og branche \fg{} (en bleu),
les réponses finales sont les \og feuilles \fg{} (en rouge et vert).
\begin{figure}[h]
\centering\small
\begin{tikzpicture}
\def\DeltaX{1.5}
\def\DeltaY{1.25}

\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorblue1] (A1) at (3.125*\DeltaX,0*\DeltaY) {Est-ce le weekend ?\vphantom{Àq}};

\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorblue1] (B1) at (1.625*\DeltaX,-1*\DeltaY) {Réunion ou cours dans l'agenda ?\vphantom{Àq}};
\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorred1] (B2) at (4.625*\DeltaX,-1*\DeltaY) {se reposer\vphantom{Àq}};

\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorblue1] (C1) at (.5*\DeltaX,-2*\DeltaY) {Résultats disponibles ?\vphantom{Àq}};
\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorred1] (C2) at (2.75*\DeltaX,-2*\DeltaY) {y aller\vphantom{Àq}};

\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorblue1] (D1) at (-2*\DeltaX,-3*\DeltaY) {Calculs en cours ?\vphantom{Àq}};
\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorblue1] (D2) at (2.75*\DeltaX,-3*\DeltaY) {Retours sur le manuscrit ?\vphantom{Àq}};

\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorred1] (E1) at (-3*\DeltaX,-4*\DeltaY) {les lancer\vphantom{Àq}};
\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorred1] (E2) at (-1*\DeltaX,-4*\DeltaY) {les contrôler\vphantom{Àq}};
\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorblue1] (E3) at (1.5*\DeltaX,-4*\DeltaY) {Chapitre terminé ?\vphantom{Àq}};
\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorgreen1] (E4) at (4*\DeltaX,-4*\DeltaY) {les appliquer\vphantom{Àq}};

\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorgreen1] (F1) at (.5*\DeltaX,-5*\DeltaY) {rédiger\vphantom{Àq}};
\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorblue1] (F2) at (2.5*\DeltaX,-5*\DeltaY) {Chapitre relu ?\vphantom{Àq}};

\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorgreen1] (G1) at (1.5*\DeltaX,-6*\DeltaY) {relire\vphantom{Àq}};
\node [draw, thick, rectangle, rounded corners = 5pt, fill = ltcolorgreen1] (G2) at (3.5*\DeltaX,-6*\DeltaY) {envoyer pour relecture\vphantom{Àq}};

\draw [thick, -latex, ltcolorred] (A1) to (B1) ;
\draw [thick, -latex, ltcolorgreen] (A1) to (B2) ;
\draw (A1.south) node [below] {{\color{ltcolorred}non} {\color{ltcolorgreen}oui}};

\draw [thick, -latex, ltcolorred] (B1) to (C1) ;
\draw [thick, -latex, ltcolorgreen] (B1) to (C2) ;
\draw (B1.south) node [below] {{\color{ltcolorred}non} {\color{ltcolorgreen}oui}};

\draw [thick, -latex, ltcolorred] (C1) to (D1) ;
\draw [thick, -latex, ltcolorgreen] (C1) to (D2) ;
\draw (C1.south) node [below] {{\color{ltcolorred}non} {\color{ltcolorgreen}oui}};

\draw [thick, -latex, ltcolorred] (D1) to (E1) ;
\draw [thick, -latex, ltcolorgreen] (D1) to (E2) ;
\draw (D1.south) node [below] {{\color{ltcolorred}non} {\color{ltcolorgreen}oui}};

\draw [thick, -latex, ltcolorred] (D2) to (E3) ;
\draw [thick, -latex, ltcolorgreen] (D2) to (E4) ;
\draw (D2.south) node [below] {{\color{ltcolorred}non} {\color{ltcolorgreen}oui}};

\draw [thick, -latex, ltcolorred] (E3) to (F1) ;
\draw [thick, -latex, ltcolorgreen] (E3) to (F2) ;
\draw (E3.south) node [below] {{\color{ltcolorred}non} {\color{ltcolorgreen}oui}};

\draw [thick, -latex, ltcolorred] (F2) to (G1) ;
\draw [thick, -latex, ltcolorgreen] (F2) to (G2) ;
\draw (F2.south) node [below] {{\color{ltcolorred}non} {\color{ltcolorgreen}oui}};

%\draw (A.south) node [below] {{\color{ltcolorred}non} {\color{ltcolorgreen}oui}};
%\draw (B.south) node [below] {{\color{ltcolorgreen}oui} \qquad\qquad {\color{ltcolorred}non}};
%\draw (C.south) node [below] {\quad {\color{ltcolorred}non} {\color{ltcolorgreen}oui}};
%\draw (D.south) node [below] {{\color{ltcolorred}non} {\color{ltcolorgreen}oui}};
%\draw (E.south) node [below] {{\color{ltcolorred}non} {\color{ltcolorgreen}oui}};
\end{tikzpicture}
\caption[Exemple d'un arbre de décision.]{Exemple d'un arbre de décision utilisable par un doctorant.}
\label{fig-decision_tree_schema}
\end{figure}
\par
De tels arbres peuvent être utilisés avec des variables numériques.
Dans ce cas, les questions consistent en une condition sur l'une des variables, par exemple $\pT^{\mu} > \SI{50}{\GeV}$.
Le choix de la variable ($\pT^{\mu}$) et de la coupure correspondante (\SI{50}{\GeV}) à utiliser pour former deux nouvelles branches $b_1$ (condition fausse) et $b_2$ (condition vraie) se base sur la similarité $S$, définie comme
\begin{equation}
S = \frac{1}{N\,n} \left(\sum_{i=1}^N \sum_{j=1}^n x_{j,i} \right)^2
\end{equation}
où $N$ est la taille du jeu de données d'entraînement (quantité d'échantillons),
$n$ le nombre de variables d'entrée différentes
et $x_{j,i}$ la valeur de la variable $x_j$ dans le $i$\up{e} échantillon.
\par
Le gain $G$ obtenu par la création de deux nouvelles branches $b_1$ et $b_2$ s'exprime
\begin{equation}
G = S_{b_1} + S_{b_2} - S_{b_1+b_2}
\end{equation}
avec
$S_{b_1+b_2}$ la similarité du jeu de donnée non séparé,
$S_{b_1}$ ($S_{b_2}$) la similarité du jeu de donnée se retrouvant dans la branche $b_1$ ($b_2$).
La condition retenue pour former les deux branches est celle présentant le gain le plus élevé.
Ce processus est alors itéré sur chacune des nouvelles branches, jusqu'à ce que:
\begin{itemize}
\item le gain soit inférieur à $\gamma$;
\item la profondeur de l'arbre (nombre de conditions successives) est supérieure à \MaxDepth.
\item la quantité d'échantillons dans une branche est inférieure à \MinChildWeight.
\end{itemize}
Les paramètres $\gamma$, \MaxDepth\ et \MinChildWeight, fixés par l'utilisateur, sont nommés \og hyper-paramètres \fg.
Ils ne doivent pas être confondus avec les paramètres propres à l'arbre, déterminés lors de la construction des branches.
%Par défaut, $\gamma=0$ et $\MinChildWeight=1$.
\subsection{\emph{Gradient Boosting}}\label{chapter-ML-section-XGB-grad_boost}
La technique du \emph{Gradient Boosting} consiste en
l'utilisation de modèles simples,
ici des arbres de décision,
pour obtenir un modèle global plus robuste.
La construction se fait de manière itérative.
\par
À chaque étape $k\geq1$,
un arbre de décision $M_k$ nommé estimateur est construit avec pour objectif de prédire
\begin{equation}
\ytruei - F_{k-1}(\vec{x}_i)
\end{equation}
pour une entrée $\vec{x}_i$,
avec
\ytruei\ la valeur que doit prédire le modèle global pour l'entrée $\vec{x}_i$
et
$F_{k-1}$ la fonction du modèle global issu de l'étape ${k-1}$,
$F_0$ étant égale à $M_0$, l'arbre de décision obtenu sans \emph{Gradient Boosting}.
Le modèle $M_k$ corrige donc l'écart résiduel des prédictions $\set{\ypredi}$ du modèle global à $\set{\ytruei}$.
Les prédictions $F_k$ du modèle global s'expriment alors
\begin{equation}
\ypredi = F_k(\vec{x}_i) = F_{k-1}(\vec{x}_i) + \eta\,M_k(\vec{x}_i)
\end{equation}
avec
$\eta$ le taux d'apprentissage, inférieur à 1, permettant de corriger progressivement l'écart résiduel.
L'itération s'arrête lorsque le nombre maximal d'estimateurs \Nestimators\ est atteint.
Les grandeurs $\eta$ et \Nestimators\ sont également des hyper-paramètres.
%\emph{The Elements of statistical learning} : Trees have one aspect that prevents them from bering the ideal tool for predictive learning, namely inaccuracy. --> they work great with the data used to create them, but they are not flexible when it comes to classifying new samples...
\subsection{Fonction de coût et \emph{Gradient Descent}}\label{chapter-ML-section-loss}
Une fonction de coût (\emph{loss function}) compare les prédictions d'un modèle aux valeurs vraies.
Elle doit être différentiable et est définie de manière à être minimale lorsque les prédictions sont égales aux valeurs vraies, \ie\ lorsque le modèle est parfait.
Les fonctions de coûts les plus répandues sont:
\begin{description}
\item[MSE] \emph{Mean Squared Error} ou erreur quadratique moyenne,
\begin{equation}
\Loss_\text{MSE}(\set{\ytruei}, \set{\ypredi}) = \frac{1}{2N} \sum_{i=1}^N \left( \ypredi - \ytruei \right)^2
\label{eq-loss_MSE}
\mend[;]
\end{equation}
\item[MAE] \emph{Mean Absolute Error} ou erreur absolue moyenne,
\begin{equation}
\Loss_\text{MAE}(\set{\ytruei}, \set{\ypredi}) = \frac{1}{N} \sum_{i=1}^N \left| \ypredi - \ytruei \right|
\label{eq-loss_MAE}
\mend[;]
\end{equation}
\item[MAPE] \emph{Mean Absolute Percentile Error} ou erreur absolue relative moyenne,
\begin{equation}
\Loss_\text{MAE}(\set{\ytruei}, \set{\ypredi}) = \frac{100}{N} \sum_{i=1}^N \left| \frac{\ypredi - \ytruei}{\ytruei} \right|
\label{eq-loss_MAPE}
\mend
\end{equation}
\end{description}
\par
L'objectif du modèle $M_k$ défini dans la section précédente est de prédire, pour $\vec{x}_i$,
\begin{equation}
\ytruei - F_{k-1}(\vec{x}_i)
=
- \pdv{\Loss_\text{MSE}(\ytruei, F_{k-1}(\vec{x}_i))}{F_{k-1}(\vec{x}_i)}
\mend
\end{equation}
Il est ainsi possible de généraliser le \emph{Gradient Boosting}
en considérant que l'objectif de $M_k$ est de prédire
\begin{equation}
- \pdv{\Loss(\ytruei, F_{k-1}(\vec{x}_i))}{F_{k-1}(\vec{x}_i)}
=
- \grad_{F_{k-1}(\vec{x}_i)} \left(\Loss(\ytruei, F_{k-1}(\vec{x}_i))\right)
\end{equation}
avec \Loss\ une fonction de coût quelconque.
Il s'agit du \emph{Gradient Descent},
où l'objectif est de minimiser \Loss.
La fonction de coût est un hyper-paramètre du modèle.
\subsection{Sous-entraînement et surentraînement}
La construction d'un modèle, aussi appelé \og entraînement \fg,
est un processus itératif
visant à minimiser la fonction de coût.
Dans le cas des arbres de décision améliorés créés avec \XGBOOST,
l'entraînement cesse lorsque le nombre d'estimateur maximal est atteint, lorsqu'il est renseigné.
Dans tous les cas, il est légitime de se demander si le modèle obtenu à la fin de l'entraînement est optimal.
\par
Il faut que l'entraînement soit suffisamment long pour que le modèle propose les prédictions les plus précises possible.
Autrement dit, il faut que le modèle ait le temps d'apprendre.
S'il ne l'a pas, les prédictions ne sont pas aussi précises qu'elles pourraient l'être, c'est le sous-entraînement.
La valeur de la fonction de coût appliquée au jeu de données d'entraînement diminuant lors de l'apprentissage,
un critère pourrait être de l'utiliser afin de déterminer si le modèle apprend encore ou non.
Arrivé à un plateau, le modèle ne s'améliore plus et l'entraînement s'arrête.
\par
Cette approche masquerait toutefois une spécialisation du modèle.
En effet, un modèle peut apprendre à prédire parfaitement $\set{\ytruei}$ sur le jeu de données d'entraînement,
ce qui correspond à une fonction de coût nulle,
mais être moins bon qu'un modèle entraîné moins longtemps lorsqu'il est utilisé sur d'autres données.
C'est le surentraînement.
Cet effet peut être évité en utilisant un jeu de données dit de \og validation \fg,
non utilisé pour régler les paramètres du modèle.
\par
L'intérêt du jeu de validation est illustré sur la figure~\ref{fig-underfitting_and_overfitting}.
Un modèle sous-entraîné ou dont l'entraînement est optimal présente des erreurs similaires dans les deux jeux de données.
Dans le cas d'un surentraînement, les erreurs continuent à diminuer sur le jeu d'entraînement, mais pas sur le jeu de validation.
Une fonction d'évaluation $E$, éventuellement égale à la fonction de coût \Loss, permet de quantifier ces erreurs et de mettre fin à l'entraînement avant de surentraîner le modèle.
Il s'agit de l'arrêt prématuré (\emph{early stopping}).
\begin{figure}[h]
\centering
\input{\PhDthesisdir/plots_and_images/my_plots/ML/overfitting_and_early_stopping/examples-pyplot.pgf}
\caption[Illustrations du sous-entraînement et du surentraînement.]{Illustrations du sous-entraînement et du surentraînement.
Un même modèle est peu (gauche), suffisamment (milieu) ou trop entraîné (droite). Ses prédictions (ordonnées) en fonction de l'entrée (abscisses) sont tracées en vert.
Le jeu de données d'entraînement (de validation) est représenté par des croix bleues (rouges) sur la ligne du haut (bas).}
\label{fig-underfitting_and_overfitting}
\end{figure}
\par
Dans le cas des arbres de décision améliorés, une itération de l'entraînement consiste en l'ajout d'un estimateur, comme exposé dans la section~\ref{chapter-ML-section-XGB-grad_boost}.
Un arrêt prématuré est réalisé lorsque l'erreur quadratique moyenne ne diminue pas sur le jeu de validation pendant 5 itérations.