\subsection{Modèle de vraisemblance}\label{chapter-HTT_analysis-section-signal_extraction-likelihood}
% AN 2013 171, p. 31
La fonction de vraisemblance \LKH\ à maximiser est définie par
le produit des probabilités poissoniennes $\Poisson (n_i | \nu_i(\mu,\theta))$ d'observer $n_i$ événements dans chaque segment $i$ de l'histogramme de la variable discriminante utilisée
selon
\begin{equation}
\LKH(n_i | \mu,\theta)
=
\prod_i \Poisson(n_i | \nu_i(\mu,\theta))
\cdot
\prod_j \Constraint(\theta_j, \tilde{\theta}_j)
\msep
\Poisson(n_i | \nu_i(\mu,\theta))
=
\frac{\nu_i^{n_i}}{{n_i}!}\eexp{-\nu_i}
\end{equation}
où
\begin{itemize}
\item $\nu_i$ est le nombre d'événements attendus dans ce segment dans l'hypothèse \hypSB, \ie
\begin{equation}
\nu_i(\mu,\theta) = \mu \, s(\theta) + b(\theta)
\end{equation}
avec
$s$ le nombre d'événements de signal
et
$b$ le nombre d'événements de bruit de fond.
Lorsque $\mu=0$, $\nu_i$ correspond donc au nombre d'événements attendus dans l'hypothèse \hypB;
\item $\mu$ est le modificateur d'intensité du signal (\emph{signal strength modifier}).
Il représente la fréquence du signal, indéterminée, par rapport à une section efficace de référence, par exemple la section efficace de production du boson de Higgs \higgs;
\item $\theta$ est un paramètre de nuisance correspondant à une source d'incertitude présentée section~\ref{chapter-HTT_analysis-section-systematics}.
Les variations de ces paramètres changent la quantité d'événements de signal $s_i$ et de bruit de fond $b_i$ attendus dans le segment $i$;
\item $j$ est un indice courant sur les différentes contraintes \Constraint\ connues sur les paramètres de nuisance.
Chacune de ces contraintes représente la probabilité que ce paramètre prenne la valeur $\theta_j$, sachant que la meilleure estimation de ce dernier est $\tilde{\theta}_j$, obtenue par des mesures annexes.
\end{itemize}
La forme de la contrainte \Constraint\ dépend du type d'incertitude et est discutée ci-après.
\subsubsection{Incertitudes de normalisation}
%Les contraintes sur les incertitudes de normalisation sont modélisées par des fonctions de densité de probabilité log-normale ou Gamma.
%\par
Les contraintes sur les incertitudes correspondant à des facteurs multiplicatifs sur la quantité d'événements de signal ou de bruit de fond, par exemple les facteurs d'échelle, sont représentées par des fonctions de densité de probabilité log-normales,
\begin{equation}
\eval{\Constraint(\theta, \tilde{\theta})}_{\text{facteurs}}
=
\frac{1}{\sqrt{2\pi}\ln\kappa}\,\frac{1}{\theta}\,\exp(-\frac{(\ln(\theta/\tilde{\theta})^2}{2(\ln\kappa)^2})
\end{equation}
où $\kappa$ vaut $1+x$ avec $x$ l'incertitude relative sur l'observable contrainte.
Par exemple, pour une incertitude de \SI{10}{\%}, $\kappa=\num{1.10}$.
\par
Les contraintes sur les incertitudes d'origine statistique, par exemple les quantités d'événements observés dans les régions de contrôle, sont représentées par des fonctions de densité de probabilité Gamma,
\begin{equation}
\eval{\Constraint(\theta, \tilde{\theta})}_{\text{stat}}
=
\frac{1}{\kappa \, \tilde{\theta}!} \left(\frac{\theta}{\kappa}\right)^{\tilde{\theta}} \exp(-\frac{\theta}{\kappa})
\end{equation}
où $\kappa$ est le rapport attendu entre $\theta$ et $\tilde{\theta}$.
La valeur de $\kappa$ a sa propre incertitude, généralement traitée comme une contrainte log-normale supplémentaire.
\subsubsection{Incertitudes de forme}
Les incertitudes systématiques de forme sur les distributions des variables discriminantes du signal ainsi que du bruit de fond sont traitées par la technique du \og morphing vertical \fg.
Pour chaque source d'incertitude, une distribution centrale (ou nominale) ainsi que celles correspondant à des variations de $\pm1\sigma$ de l'incertitude sont déterminées.
Un paramètre de nuisance $\lambda$ est ajouté au modèle de vraisemblance afin d'interpoler entre ces différentes distributions.
\par
Les effets de plusieurs incertitudes de forme sont additifs.
Soient
$h_0$ la distribution centrale,
$h_j^+$ ($h_j^-$) la distribution correspondant à une variation de $+1\sigma$ ($-1\sigma$) de l'incertitude $j$ et
$\lambda_j$ le paramètre de nuisance ainsi obtenu.
Le modèle de distribution est donné par
\begin{equation}
h(\vec{\lambda}) = h_0 + \sum_j \left( a(\lambda_j)h_j^+ + b(\lambda_j) h_0 + c(\lambda_j)h_j^- \right)
\label{eq-h_interpolation}
\end{equation}
avec
\begin{equation}
a = \left\lbrace
\begin{aligned}
\lambda(\lambda+1)/2 &\msep \abs{\lambda}\leq1 \mend[,] \\
0 &\msep \lambda<-1 \mend[,] \\
\lambda &\msep \lambda>+1 \mend[,]
\end{aligned}
\right.
\qquad
b = \left\lbrace
\begin{aligned}
-\lambda^2 &\msep \abs{\lambda}\leq1 \mend[,] \\
-\abs{\lambda} &\msep \abs{\lambda}>1 \mend[,]
\end{aligned}
\right.
\qquad
c = \left\lbrace
\begin{aligned}
\lambda(\lambda-1)/2 &\msep \abs{\lambda}\leq1 \mend[,] \\
\abs{\lambda} &\msep \lambda<-1 \mend[,] \\
0 &\msep \lambda>+1 \mend
\end{aligned}
\right.
\end{equation}
L'interpolation~\eqref{eq-h_interpolation} est réalisée lors de la maximisation de la fonction de vraisemblance.
\subsubsection{Incertitudes statistiques}
\paragraph{Principe}
L'incertitude statistique dans les distributions des variables discriminantes et prise en compte par la méthode de Barlow-Beeston~\cite{BarlowBeeston,BarlowBeeston2}.
La quantité d'événements dans chaque segment peut varier dans l'incertitude statistique type, ce qui revient à créer une incertitude de forme.
\par
Afin de réduire la quantité de paramètres de nuisance, et donc le temps de calcul, la procédure suivante est suivie dans chaque segment:
\begin{enumerate}
\item Les processus $i$ contenant $x_i$ événements et une incertitude statistique $e_i$ tels que $e_i/x_i$ est supérieur à une valeur \inlinecode{cpp}{AddThreshold} choisie sont sélectionnés.
\item L'incertitude totale $e_\text{tot}$ sur l'ensemble de ces processus est déterminée selon
\begin{equation}
e_\text{tot}^2 = \sum_{j\in\set{i}} e_j^2
\mend
\end{equation}
\item Les processus $i$ sont classés par valeur croissante de $e_i^2/e_\text{tot}^2$.
\item Dans l'ordre des processus obtenu, les incertitudes statistiques sont supprimées tant que la somme des carrés des incertitudes supprimées est inférieure à une fraction de l'incertitude totale au carré \inlinecode{cpp}{merge_threshold} choisie.
\item Les incertitudes restantes sont multipliées par un facteur permettant de conserver une incertitude totale constante.
\end{enumerate}
Il s'agit donc de regrouper les incertitudes.
\paragraph{Contribution personnelle}
Lors de ma thèse, j'ai observé que l'incertitude totale pouvait varier lors de cette procédure, comme cela est illustré sur la figure~\ref{fig-BBB_issue_2017_mt}.
Dans le dernier segment, il apparaît clairement sur le rapport données sur bruit de fond que l'incertitude totale sur le bruit de fond est modifiée par le regroupement.
Il s'agissait d'un bug que j'ai identifié et corrigé~\cite{BBB_PR} dans le code de \COMBINE.
\begin{figure}[h]
\centering

\subcaptionbox{Sans regroupement.}[.45\textwidth]
{\LARGE\includegraphics[width=.45\textwidth]{/home/torterotot/Documents/PhD-Thesis/plots_and_images/BBB_issue/prefit_plots_mt_inclusive-no_merging.tex}}
\hfill
\subcaptionbox{Avec regroupement.}[.45\textwidth]
{\LARGE\includegraphics[width=.45\textwidth]{/home/torterotot/Documents/PhD-Thesis/plots_and_images/BBB_issue/prefit_plots_mt_inclusive-do_merging.tex}}

\caption[Distributions de \mTtot\ avec et sans regroupement des incertitudes.]{Distributions de \mTtot\ avec et sans regroupement des incertitudes pour le canal \mu\tauh\ en 2017. Le tracé des données s'arrête à \SI{130}{\GeV}, avant la zone où le signal est attendu.}
\label{fig-BBB_issue_2017_mt}
\end{figure}
\par
Dans le code initial,
pour chaque segment des distributions dans chaque catégorie,
les processus $i$ peuvent être classés dans cinq groupes:
\begin{description}
\item[groupe Z] $x_i = 0$ et $e_i = 0$ (processus non présent dans le segment) ou $e_i/x_i$ inférieur à \inlinecode{cpp}{AddThreshold}, non traités par la procédure de regroupement;
\item[groupe A] incertitude à supprimer et $0 < e_i < x_i$;
\item[groupe B] incertitude à conserver et $0 < e_i < x_i$;
\item[groupe C] incertitude à supprimer et $0 < x_i \leq e_i$;
\item[groupe D] incertitude à conserver et $0 < x_i \leq e_i$.
\end{description}
Les processus tels que $0 < e_i < x_i$ (groupes A et B)
possèdent un attribut \inlinecode{cpp}{can_expand = true}
et sont ceux dont l'incertitude statistique est renormalisée (\emph{expand}) à l'étape 5 par un facteur
\begin{equation}
\text{\inlinecode{cpp}{expand = std::sqrt(1. / (1. - (removed / tot_bbb_added)))}}
\Leftrightarrow
E = \sqrt{\frac{1}{1-\frac{R}{T}}}
\end{equation}
avec
\begin{equation}
R = \text{\inlinecode{cpp}{removed}} = \sum_{i\in{\set{\text{A},\text{C}}}} e_i^2
\msep
T = \text{\inlinecode{cpp}{tot_bbb_added}} = \sum_{i\in{\set{\text{A},\text{B}}}} e_i^2
\mend
\end{equation}
\par
Ainsi, l'incertitude totale après regroupement s'exprime en fonction des incertitudes de chaque processus $i$ avant regroupement selon
\begin{align}
e_\text{tot,après} ^2
&=
\sum_{i\in{\set{\text{A}}}} (E\times 0\times e_i)^2
+
\sum_{i\in{\set{\text{B}}}} (E\times e_i)^2
+
\sum_{i\in{\set{\text{C}}}} (0\times e_i)^2
+
\sum_{i\in{\set{\text{D},\text{Z}}}} (e_i)^2
\nonumber\\&
=
E^2 \sum_{i\in{\set{\text{B}}}} e_i^2
+
\sum_{i\in{\set{\text{D},\text{Z}}}} e_i^2
\mend
\end{align}
Or,
\begin{equation}
E^2
=
\frac{1}{1-\frac{R}{T}}
=
\frac{T}{T-R}
=
\frac{\sum_{i\in{\set{\text{A},\text{B}}}} e_i^2}{\sum_{i\in{\set{\text{A},\text{B}}}} e_i^2-\sum_{i\in{\set{\text{A},\text{C}}}} e_i^2}
=
\frac{\sum_{i\in{\set{\text{A},\text{B}}}} e_i^2}{\sum_{i\in{\set{\text{B}}}} e_i^2-\sum_{i\in{\set{\text{C}}}} e_i^2}
\end{equation}
soit
\begin{equation}
e_\text{tot,après} ^2
=
\frac{\sum_{i\in{\set{\text{A},\text{B}}}} e_i^2}{\sum_{i\in{\set{\text{B}}}} e_i^2-\sum_{i\in{\set{\text{C}}}} e_i^2}
\times
\sum_{i\in{\set{\text{B}}}} e_i^2
+
\sum_{i\in{\set{\text{D},\text{Z}}}} e_i^2
\label{eq-e_tot_after_with_C}
\end{equation}
ce qui est différent de l'erreur initiale dans le cas général.
Cette formule a été testée numériquement, ce qui a permis de confirmer la bonne compréhension du code initial.
\par
Le problème vient du traitement du groupe C, \ie\ des processus dont l'incertitude est supprimée mais dont la quantité d'événement est inférieure à celle-ci.
En effet, ils ne sont pas pris en compte dans le calcul de $T$.
Le correctif proposé~\cite{BBB_PR} est de refuser le cas du groupe C et de rediriger ces processus dans le groupe D.
Alors, le groupe C étant forcément un ensemble vide, l'équation~\eqref{eq-e_tot_after_with_C} se réécrit
\begin{equation}
e_\text{tot,après} ^2
=
\frac{\sum_{i\in{\set{\text{A},\text{B}}}} e_i^2}{\sum_{i\in{\set{\text{B}}}} e_i^2}
\times
\sum_{i\in{\set{\text{B}}}} e_i^2
+
\sum_{i\in{\set{\text{D},\text{Z}}}} e_i^2
=
\sum_{i\in{\set{\text{A},\text{B}}}} e_i^2
+
\sum_{i\in{\set{\text{D},\text{Z}}}} e_i^2
=
e_\text{tot,avant} ^2
\mend[,]
\end{equation}
l'incertitude totale est donc bien conservée.
\par
Dans le cas d'étude de la figure~\ref{fig-BBB_issue_2017_mt}, ce correctif introduit six paramètres de nuisance supplémentaires, ce qui reste raisonnable en terme de charge computationnelle.
En effet, les processus devant entrer dans le groupe C sont peu nombreux.